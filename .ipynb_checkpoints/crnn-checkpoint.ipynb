{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84a1358b-013a-4012-ae5a-1e78c77c6539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def bbox_loss(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "def create_detection_model(input_shape, num_classes):\n",
    "    base_model = tf.keras.applications.MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "    x = base_model.output\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(1024, activation='relu')(x)\n",
    "    x = layers.Dense(num_classes * 4, activation='sigmoid')(x)  # 4 for bounding box coordinates\n",
    "    detection_model = models.Model(inputs=base_model.input, outputs=x)\n",
    "    return detection_model\n",
    "\n",
    "input_shape = (128, 128, 3)\n",
    "num_classes = 1  # 只检测一个类别，即字符\n",
    "detection_model = create_detection_model(input_shape, num_classes)\n",
    "detection_model.compile(optimizer='adam', loss=bbox_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b75a1ec-17cd-4c1c-adf6-171e08f2cc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_crnn_model(imgH, nc, nclass, nh):\n",
    "    input_data = layers.Input(shape=(imgH, None, nc), name='input')\n",
    "\n",
    "    cnn = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(input_data)\n",
    "    cnn = layers.MaxPooling2D(pool_size=(2, 2))(cnn)\n",
    "    cnn = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(cnn)\n",
    "    cnn = layers.MaxPooling2D(pool_size=(2, 2))(cnn)\n",
    "    cnn = layers.Conv2D(256, (3, 3), padding='same', activation='relu')(cnn)\n",
    "    cnn = layers.BatchNormalization()(cnn)\n",
    "    cnn = layers.Conv2D(256, (3, 3), padding='same', activation='relu')(cnn)\n",
    "    cnn = layers.MaxPooling2D(pool_size=(2, 1))(cnn)\n",
    "    cnn = layers.Conv2D(512, (3, 3), padding='same', activation='relu')(cnn)\n",
    "    cnn = layers.BatchNormalization()(cnn)\n",
    "    cnn = layers.Conv2D(512, (3, 3), padding='same', activation='relu')(cnn)\n",
    "    cnn = layers.MaxPooling2D(pool_size=(2, 1))(cnn)\n",
    "    cnn = layers.Conv2D(512, (2, 2), padding='valid', activation='relu')(cnn)\n",
    "\n",
    "    cnn = layers.Reshape(target_shape=(-1, 512))(cnn)\n",
    "    rnn = layers.Bidirectional(layers.LSTM(nh, return_sequences=True))(cnn)\n",
    "    rnn = layers.Bidirectional(layers.LSTM(nh, return_sequences=True))(rnn)\n",
    "    dense = layers.Dense(nclass, activation='softmax')(rnn)\n",
    "\n",
    "    crnn_model = models.Model(inputs=input_data, outputs=dense)\n",
    "    return crnn_model\n",
    "\n",
    "imgH = 32\n",
    "nc = 1  # 输入图像的通道数 (灰度图像)\n",
    "nclass = 10 + 1  # 10个数字和一个空白字符\n",
    "nh = 256  # LSTM的隐藏单元数\n",
    "\n",
    "crnn_model = create_crnn_model(imgH, nc, nclass, nh)\n",
    "crnn_model.compile(optimizer='adam', loss='ctc_loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95f8291-6522-4d7a-9104-4c2f3507791b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c83c8e-8178-40eb-9ada-68c696001277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建目标检测模型\n",
    "input_shape = (128, 128, 3)\n",
    "num_classes = 10  # 对应字符数\n",
    "detection_model = create_detection_model(input_shape, num_classes)\n",
    "\n",
    "# 创建CRNN模型\n",
    "imgH = 32\n",
    "nc = 1\n",
    "nclass = 10 + 1\n",
    "nh = 256\n",
    "crnn_model = create_crnn_model(imgH, nc, nclass, nh)\n",
    "\n",
    "# 将目标检测模型和CRNN模型结合\n",
    "inputs = layers.Input(shape=(128, 128, 3))\n",
    "bboxes = detection_model(inputs)\n",
    "# 将边界框裁剪后的图像送入CRNN模型进行字符识别\n",
    "# 假设 `crop_and_resize` 是一个函数，用于裁剪图像并调整为CRNN模型输入大小\n",
    "cropped_images = crop_and_resize(inputs, bboxes, imgH, 100)\n",
    "crnn_outputs = crnn_model(cropped_images)\n",
    "\n",
    "combined_model = models.Model(inputs=inputs, outputs=crnn_outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
