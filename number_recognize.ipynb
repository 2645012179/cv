{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46a5963f-8ab0-4563-8a41-5e7d6eae78f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2d3aed8-1418-4e34-afd3-d2f4b01e5122",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "numbers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "889e8ee4-9795-4258-97f1-8becf3f1e9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_names_labels = pd.read_csv('images/labels.csv')\n",
    "filenames = data_names_labels['filename']\n",
    "labels = data_names_labels['number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25bd9ea4-902f-43a7-88bb-07220a0a6cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'images/'\n",
    "locpath = 'train/'\n",
    "for filename in filenames:\n",
    "    imagepath = filepath + filename\n",
    "    blocktail = filename.replace('.jpg','')\n",
    "    location_path = locpath + blocktail + '.xml'\n",
    "    \n",
    "    tree = ET.parse(location_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # 提取对象和边界框数据\n",
    "    data = []\n",
    "    for obj in root.findall('object'):\n",
    "        name = obj.find('name').text\n",
    "        bndbox = obj.find('bndbox')\n",
    "        xmin = int(bndbox.find('xmin').text)\n",
    "        ymin = int(bndbox.find('ymin').text)\n",
    "        xmax = int(bndbox.find('xmax').text)\n",
    "        ymax = int(bndbox.find('ymax').text)\n",
    "        data.append([name, xmin, ymin, xmax, ymax])\n",
    "    \n",
    "    # 转换为 DataFrame\n",
    "    df = pd.DataFrame(data, columns=['name', 'xmin', 'ymin', 'xmax', 'ymax'])\n",
    "\n",
    "    for num in range(len(df)):\n",
    "        \n",
    "        xmin = df['xmin'][num]\n",
    "        xmax = df['xmax'][num]\n",
    "        ymin = df['ymin'][num]\n",
    "        ymax = df['ymax'][num]\n",
    "    \n",
    "        image = cv2.imread(imagepath, cv2.IMREAD_COLOR)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        # 中值滤波去噪\n",
    "        gray = cv2.medianBlur(gray, 5)\n",
    "        # 去照光\n",
    "        adaptive_thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "        # 计算透视变换矩阵\n",
    "        points = np.array([[xmin, ymin], [xmax, ymin], [xmax, ymax], [xmin, ymax]], dtype='float32')\n",
    "        width = xmax - xmin\n",
    "        height = ymax - ymin\n",
    "        dst_points = np.array([[0, 0], [width - 1, 0], [width - 1, height - 1], [0, height - 1]], dtype='float32')\n",
    "        \n",
    "        matrix = cv2.getPerspectiveTransform(points, dst_points)\n",
    "        \n",
    "        # 进行透视变换\n",
    "        warped = cv2.warpPerspective(adaptive_thresh, matrix, (width, height))\n",
    "        image = cv2.resize(warped,(20,32))\n",
    "\n",
    "        # 归一化处理\n",
    "        normalized_image = image / 255.0\n",
    "        \n",
    "        images.append(normalized_image)\n",
    "        numbers.append(df['name'][num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db01d691-d1b2-46af-9a12-19a2a929cd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(images)\n",
    "numbers = np.array(numbers, dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34c7036e-aa58-4bf0-8ae4-8f3e02246307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5039, 32, 20, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = np.expand_dims(images, axis=-1)\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7929eb38-bd6b-4ad0-9236-0caa3dc863d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(20, 32, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df5b5871-1fd6-4163-8a66-def39d1081d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(images,numbers,test_size=0.2,random_state=50)\n",
    "num_classes = 10\n",
    "y_train = to_categorical(y_train,num_classes=num_classes)\n",
    "y_test = to_categorical(y_test,num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13267850-a942-4053-a614-c7984518ae9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5244 - loss: 1.4286 - val_accuracy: 0.9236 - val_loss: 0.2566\n",
      "Epoch 2/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9261 - loss: 0.2755 - val_accuracy: 0.9573 - val_loss: 0.1381\n",
      "Epoch 3/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9540 - loss: 0.1672 - val_accuracy: 0.9643 - val_loss: 0.1025\n",
      "Epoch 4/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9625 - loss: 0.1185 - val_accuracy: 0.9603 - val_loss: 0.1132\n",
      "Epoch 5/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9779 - loss: 0.0787 - val_accuracy: 0.9663 - val_loss: 0.1012\n",
      "Epoch 6/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9800 - loss: 0.0728 - val_accuracy: 0.9683 - val_loss: 0.0870\n",
      "Epoch 7/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9774 - loss: 0.0643 - val_accuracy: 0.9722 - val_loss: 0.0753\n",
      "Epoch 8/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9835 - loss: 0.0525 - val_accuracy: 0.9762 - val_loss: 0.0734\n",
      "Epoch 9/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9889 - loss: 0.0375 - val_accuracy: 0.9683 - val_loss: 0.0916\n",
      "Epoch 10/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9904 - loss: 0.0313 - val_accuracy: 0.9742 - val_loss: 0.0732\n",
      "Epoch 11/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9925 - loss: 0.0317 - val_accuracy: 0.9752 - val_loss: 0.0898\n",
      "Epoch 12/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9921 - loss: 0.0246 - val_accuracy: 0.9772 - val_loss: 0.0780\n",
      "Epoch 13/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9949 - loss: 0.0156 - val_accuracy: 0.9752 - val_loss: 0.0687\n",
      "Epoch 14/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9976 - loss: 0.0097 - val_accuracy: 0.9653 - val_loss: 0.1063\n",
      "Epoch 15/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9964 - loss: 0.0157 - val_accuracy: 0.9772 - val_loss: 0.0872\n",
      "Epoch 16/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9952 - loss: 0.0129 - val_accuracy: 0.9702 - val_loss: 0.0820\n",
      "Epoch 17/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9984 - loss: 0.0069 - val_accuracy: 0.9712 - val_loss: 0.0965\n",
      "Epoch 18/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0038 - val_accuracy: 0.9712 - val_loss: 0.0919\n",
      "Epoch 19/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0021 - val_accuracy: 0.9752 - val_loss: 0.0886\n",
      "Epoch 20/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9732 - val_loss: 0.1048\n",
      "Epoch 21/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9981 - loss: 0.0097 - val_accuracy: 0.9742 - val_loss: 0.1357\n",
      "Epoch 22/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9962 - loss: 0.0117 - val_accuracy: 0.9712 - val_loss: 0.1057\n",
      "Epoch 23/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9948 - loss: 0.0224 - val_accuracy: 0.9752 - val_loss: 0.0936\n",
      "Epoch 24/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0049 - val_accuracy: 0.9762 - val_loss: 0.1029\n",
      "Epoch 25/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9961 - loss: 0.0098 - val_accuracy: 0.9722 - val_loss: 0.0974\n",
      "Epoch 26/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9968 - loss: 0.0112 - val_accuracy: 0.9762 - val_loss: 0.0971\n",
      "Epoch 27/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9945 - loss: 0.0161 - val_accuracy: 0.9702 - val_loss: 0.0856\n",
      "Epoch 28/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9984 - loss: 0.0061 - val_accuracy: 0.9712 - val_loss: 0.0840\n",
      "Epoch 29/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9993 - loss: 0.0025 - val_accuracy: 0.9752 - val_loss: 0.0905\n",
      "Epoch 30/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.1621e-04 - val_accuracy: 0.9752 - val_loss: 0.0779\n",
      "Epoch 31/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.9367e-04 - val_accuracy: 0.9732 - val_loss: 0.0814\n",
      "Epoch 32/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.0199e-04 - val_accuracy: 0.9732 - val_loss: 0.0827\n",
      "Epoch 33/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.8097e-05 - val_accuracy: 0.9742 - val_loss: 0.0842\n",
      "Epoch 34/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.9736e-05 - val_accuracy: 0.9752 - val_loss: 0.0850\n",
      "Epoch 35/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.4013e-05 - val_accuracy: 0.9752 - val_loss: 0.0861\n",
      "Epoch 36/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.4012e-05 - val_accuracy: 0.9752 - val_loss: 0.0865\n",
      "Epoch 37/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.4715e-05 - val_accuracy: 0.9742 - val_loss: 0.0867\n",
      "Epoch 38/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.6978e-05 - val_accuracy: 0.9752 - val_loss: 0.0887\n",
      "Epoch 39/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.7425e-05 - val_accuracy: 0.9762 - val_loss: 0.0893\n",
      "Epoch 40/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.0710e-05 - val_accuracy: 0.9742 - val_loss: 0.0898\n",
      "Epoch 41/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.4128e-05 - val_accuracy: 0.9742 - val_loss: 0.0900\n",
      "Epoch 42/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.3950e-05 - val_accuracy: 0.9752 - val_loss: 0.0913\n",
      "Epoch 43/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.9909e-05 - val_accuracy: 0.9742 - val_loss: 0.0915\n",
      "Epoch 44/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.6959e-05 - val_accuracy: 0.9742 - val_loss: 0.0923\n",
      "Epoch 45/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.8893e-05 - val_accuracy: 0.9752 - val_loss: 0.0931\n",
      "Epoch 46/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.3018e-05 - val_accuracy: 0.9752 - val_loss: 0.0935\n",
      "Epoch 47/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.0917e-05 - val_accuracy: 0.9752 - val_loss: 0.0944\n",
      "Epoch 48/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.7801e-05 - val_accuracy: 0.9752 - val_loss: 0.0947\n",
      "Epoch 49/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.7984e-05 - val_accuracy: 0.9752 - val_loss: 0.0959\n",
      "Epoch 50/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.6578e-05 - val_accuracy: 0.9752 - val_loss: 0.0962\n",
      "Epoch 51/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.6608e-05 - val_accuracy: 0.9752 - val_loss: 0.0970\n",
      "Epoch 52/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.5263e-05 - val_accuracy: 0.9752 - val_loss: 0.0969\n",
      "Epoch 53/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.3280e-05 - val_accuracy: 0.9752 - val_loss: 0.0981\n",
      "Epoch 54/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.4232e-05 - val_accuracy: 0.9752 - val_loss: 0.0987\n",
      "Epoch 55/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.3192e-05 - val_accuracy: 0.9752 - val_loss: 0.0990\n",
      "Epoch 56/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.9443e-06 - val_accuracy: 0.9752 - val_loss: 0.0995\n",
      "Epoch 57/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.0765e-05 - val_accuracy: 0.9752 - val_loss: 0.1001\n",
      "Epoch 58/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.0330e-05 - val_accuracy: 0.9752 - val_loss: 0.1003\n",
      "Epoch 59/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.4278e-06 - val_accuracy: 0.9752 - val_loss: 0.1016\n",
      "Epoch 60/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.1306e-06 - val_accuracy: 0.9752 - val_loss: 0.1020\n",
      "Epoch 61/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.8248e-06 - val_accuracy: 0.9752 - val_loss: 0.1032\n",
      "Epoch 62/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.6996e-06 - val_accuracy: 0.9752 - val_loss: 0.1031\n",
      "Epoch 63/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.4693e-06 - val_accuracy: 0.9752 - val_loss: 0.1040\n",
      "Epoch 64/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.4129e-06 - val_accuracy: 0.9752 - val_loss: 0.1044\n",
      "Epoch 65/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.8183e-06 - val_accuracy: 0.9742 - val_loss: 0.1057\n",
      "Epoch 66/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.7396e-06 - val_accuracy: 0.9742 - val_loss: 0.1058\n",
      "Epoch 67/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.3235e-06 - val_accuracy: 0.9742 - val_loss: 0.1068\n",
      "Epoch 68/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.1408e-06 - val_accuracy: 0.9742 - val_loss: 0.1073\n",
      "Epoch 69/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.7398e-06 - val_accuracy: 0.9742 - val_loss: 0.1086\n",
      "Epoch 70/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.9601e-06 - val_accuracy: 0.9732 - val_loss: 0.1088\n",
      "Epoch 71/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.8683e-06 - val_accuracy: 0.9732 - val_loss: 0.1097\n",
      "Epoch 72/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.6817e-06 - val_accuracy: 0.9742 - val_loss: 0.1110\n",
      "Epoch 73/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.6566e-06 - val_accuracy: 0.9742 - val_loss: 0.1106\n",
      "Epoch 74/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.3593e-06 - val_accuracy: 0.9742 - val_loss: 0.1118\n",
      "Epoch 75/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.4824e-06 - val_accuracy: 0.9732 - val_loss: 0.1125\n",
      "Epoch 76/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.4699e-06 - val_accuracy: 0.9742 - val_loss: 0.1129\n",
      "Epoch 77/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.9009e-06 - val_accuracy: 0.9732 - val_loss: 0.1133\n",
      "Epoch 78/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.2942e-06 - val_accuracy: 0.9732 - val_loss: 0.1134\n",
      "Epoch 79/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.3626e-06 - val_accuracy: 0.9732 - val_loss: 0.1157\n",
      "Epoch 80/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.0090e-06 - val_accuracy: 0.9732 - val_loss: 0.1156\n",
      "Epoch 81/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.2020e-06 - val_accuracy: 0.9732 - val_loss: 0.1169\n",
      "Epoch 82/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.9798e-06 - val_accuracy: 0.9732 - val_loss: 0.1169\n",
      "Epoch 83/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.7604e-06 - val_accuracy: 0.9732 - val_loss: 0.1186\n",
      "Epoch 84/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.5336e-06 - val_accuracy: 0.9732 - val_loss: 0.1193\n",
      "Epoch 85/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.6218e-06 - val_accuracy: 0.9742 - val_loss: 0.1187\n",
      "Epoch 86/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.3682e-06 - val_accuracy: 0.9732 - val_loss: 0.1205\n",
      "Epoch 87/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.2588e-06 - val_accuracy: 0.9742 - val_loss: 0.1206\n",
      "Epoch 88/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.0261e-06 - val_accuracy: 0.9742 - val_loss: 0.1207\n",
      "Epoch 89/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.1051e-06 - val_accuracy: 0.9732 - val_loss: 0.1217\n",
      "Epoch 90/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.0578e-06 - val_accuracy: 0.9752 - val_loss: 0.1225\n",
      "Epoch 91/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.0969e-06 - val_accuracy: 0.9752 - val_loss: 0.1235\n",
      "Epoch 92/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.8538e-07 - val_accuracy: 0.9742 - val_loss: 0.1245\n",
      "Epoch 93/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.8422e-07 - val_accuracy: 0.9742 - val_loss: 0.1247\n",
      "Epoch 94/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.8378e-07 - val_accuracy: 0.9752 - val_loss: 0.1257\n",
      "Epoch 95/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.2692e-07 - val_accuracy: 0.9752 - val_loss: 0.1266\n",
      "Epoch 96/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.9164e-07 - val_accuracy: 0.9742 - val_loss: 0.1273\n",
      "Epoch 97/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.8678e-07 - val_accuracy: 0.9752 - val_loss: 0.1273\n",
      "Epoch 98/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.2229e-07 - val_accuracy: 0.9742 - val_loss: 0.1294\n",
      "Epoch 99/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.8992e-07 - val_accuracy: 0.9742 - val_loss: 0.1295\n",
      "Epoch 100/100\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.0962e-07 - val_accuracy: 0.9752 - val_loss: 0.1302\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, \n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f52e800-2c5a-4223-a300-9e5ccd0ed01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45be65c8-7d24-4b99-8a02-1ba52f118d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: [8 1 2 0 8 0 7 7 7 6]\n",
      "True classes: [8 1 2 0 8 0 7 7 7 6]\n"
     ]
    }
   ],
   "source": [
    "# 将概率分布转换为类别标签\n",
    "predicted_classes = np.argmax(pred, axis=1)\n",
    "\n",
    "# 如果需要将 one-hot 编码的真实标签转换回类别标签\n",
    "true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# 打印前几个预测结果和对应的真实标签\n",
    "print(\"Predicted classes:\", predicted_classes[:10])\n",
    "print(\"True classes:\", true_classes[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe63f7d-3e6c-4d74-bd7b-e45a7eb3dd1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
